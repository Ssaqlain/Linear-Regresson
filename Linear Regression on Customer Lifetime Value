library("boot") 
library("car")
data<- read.csv("Fn-UseC_-Marketing-Customer-Value-Analysis 1.csv")
summary(data)
str(data)
names(data)
data$Effective.To.Date=as.Date(data$Effective.To.Date,"%m/%d/%y")  

names(data)[names(data) == "Customer.Lifetime.Value"] <- "clv"   # Changing name of perticular column

boxplot(data$clv)     
quantile(data$clv, c(0,0.05,0.1,0.25,0.5,0.75,0.90,0.95,0.99,0.995,0.999,1))
data2 <- data[data$clv <36000, ]    ## removing the outliers
boxplot(data2$clv)
quantile(data2$clv, c(0,0.05,0.1,0.25,0.5,0.75,0.90,0.95,0.99,0.995,0.999,1))
data3 <- data[data$clv <14722, ]    ## removing outliers 
boxplot(data3$clv)
quantile(data3$clv, c(0,0.05,0.1,0.25,0.5,0.75,0.90,0.95,0.99,0.995,1))

nrow(data) - nrow(data3)                             ## Data we loose to remove outliers
(nrow(data) - nrow(data3)) / nrow(data)* 100     

data  <- data3      ## creating a backup dataset

any(is.na(data$Customer))                       # To check is there  any missing value in customer column of given data

sapply(data, function(x) sum(is.na(x)))         # To check how many missing values are in every column
data1<- na.omit(data)                           # deleting the row of missing

data<- data1[,-c(1,2,7)]                        # Dropping the redundant variable - customer id, state, date
str(data)

## Spliting data into traing and testing #######################################################
set.seed(1)                                                             # to fix randomly genrated number or samples
pintu<- split(data, sample(1:nrow(data) > round(nrow(data) * .7)))      # spliting data into two part randomly in ratio of 70:30
trainig_data <- pintu$"FALSE"                                           # assiging split data into two data set
test_data <- pintu$"TRUE"
 
## Fitting linear regreesion model #####################################################################################################
fit<- lm(clv ~ Response +	Coverage +	Education +	EmploymentStatus +	Gender +	Income +	Location.Code 
         +	Marital.Status +	Monthly.Premium.Auto +	Months.Since.Last.Claim +	Months.Since.Policy.Inception 
         +	Number.of.Open.Complaints +	Number.of.Policies +	Policy.Type +	Policy +	Renew.Offer.Type 
         +	Sales.Channel +	Total.Claim.Amount +	Vehicle.Class +	Vehicle.Size , data=trainig_data)
summary(fit)

                      ## 1st check ANOVA pvalue if p value < 0.05 atleast one of the indep. variable is affecting or contributing to dependent variable
                      ## 2nd check p value for all variable seperately
                      ##       if p value < 0.05 variable is important to the model o.w remove it.
                      ##       in case of confusion check estimate and t-value/z-value variable with lowest values should be deleted
                      ## Try to delet variables  one by one
                      ## Chechk R_square and Adj_R_square

## 2nd iteration - Removing Policy  and Policy type 
fit<- lm(clv~ Response +	Coverage +	Education +	EmploymentStatus +	Gender +	Income +	Location.Code 
         +	Marital.Status +	Monthly.Premium.Auto +	Months.Since.Last.Claim +	Months.Since.Policy.Inception 
         +	Number.of.Open.Complaints +	Number.of.Policies +	Renew.Offer.Type 
         +	Sales.Channel +	Total.Claim.Amount +	Vehicle.Class +	Vehicle.Size , data=trainig_data)
summary(fit)


##3rd iteration - Removing Sales.Channel, Total.Claim.Amount, Gender ,	Income ,	Location.Code ,Marital.Status 
fit<- lm(clv~ Response +	Coverage +	Education +	EmploymentStatus +	Monthly.Premium.Auto +	Months.Since.Last.Claim +	Months.Since.Policy.Inception 
         +	Number.of.Open.Complaints +	Number.of.Policies +	Renew.Offer.Type 
         +	Vehicle.Class +	Vehicle.Size , data=trainig_data)
summary(fit)

## 4th iteration - Removing  Months.Since.Policy.Inception, Vehicle.Class except SUV, Vehicle.Size except Small
fit<- lm(clv~ Response +	Coverage +	Education +	EmploymentStatus +Monthly.Premium.Auto +	Months.Since.Last.Claim 
         +	Number.of.Open.Complaints +	Number.of.Policies +	Renew.Offer.Type 
         +	I(Vehicle.Class=="SUV") +	I(Vehicle.Size=="Small") , data=trainig_data)
summary(fit)

## 5th iteration - Removing  Months.Since.Last.Claim, I(Vehicle.Size=="Small"), Response 
fit<- lm(clv~ 	Coverage +	Education +	EmploymentStatus +Monthly.Premium.Auto  
         +	Number.of.Open.Complaints +	Number.of.Policies +	Renew.Offer.Type 
         +	I(Vehicle.Class=="SUV")  , data=trainig_data)
summary(fit)

## 6th iteration - Removing  Education except College and High School or Below
fit<- lm(clv~ 	Coverage +	I(Education=="College")+I(Education=="High School or Below") +	EmploymentStatus 
         +Monthly.Premium.Auto  +	Number.of.Open.Complaints +	Number.of.Policies +	Renew.Offer.Type 
         +	I(Vehicle.Class=="SUV")  , data=trainig_data)
summary(fit)

## 7th iteration - Removing  Employmentstatus employed ,I(Education=="High School or Below")
fit<- lm(clv~ 	Coverage +	I(Education=="College") 
         + I(EmploymentStatus=="Medical Leave")+ I(EmploymentStatus=="Retired")+ I(EmploymentStatus=="Unemployed")
         +Monthly.Premium.Auto  +	Number.of.Open.Complaints +	Number.of.Policies +	Renew.Offer.Type 
         +	I(Vehicle.Class=="SUV")  , data=trainig_data)
summary(fit)

##Final model - Removing Vehecle Size , Marital.Status Renew.Offer.TypeOffer 3
fit<- lm(clv~ 	Coverage +	I(Education=="College") 
         + I(EmploymentStatus=="Medical Leave")+ I(EmploymentStatus=="Retired")+ I(EmploymentStatus=="Unemployed")
         +Monthly.Premium.Auto  +	Number.of.Open.Complaints +	Number.of.Policies +	Renew.Offer.Type 
         +	I(Vehicle.Class=="SUV")  , data = trainig_data)
summary(fit)

trainig_data$pred <- fitted(fit)                  # Storing  predicted or fitted values
attach(trainig_data)
(sum((abs(clv-pred))/clv))/nrow(trainig_data)     # Calculating MAPE - mean absolute percent error

## Checking of Assumption ############################################################################################
## Checking fir Autocorrelation ( there should be no linear relationship between residuals)
durbinWatsonTest(fit)          
dwt(fit)
# Checking multicollinearity
vif(fit) # should be within 2. If it is greater than 10 then serious problem
## Heteroscedasticity
bptest(fit)  # Null hypothesis -> error is homogenious (p value should be more than 0.05)
## Normality testing Null hypothesis: residuals are normallay distributed
resids <- fit$residuals
ad.test(resids) #get Anderson-Darling test for normality 

###########################################################################################################################
############## Testing the model on test data ############################################################################
###########################################################################################################################
fit1<- lm(clv~ 	Coverage +	I(Education=="College") 
          + I(EmploymentStatus=="Medical Leave")+ I(EmploymentStatus=="Retired")+ I(EmploymentStatus=="Unemployed")
          +Monthly.Premium.Auto  +	Number.of.Open.Complaints +	Number.of.Policies +	Renew.Offer.Type 
          +	I(Vehicle.Class=="SUV")  , data=test_data)
summary(fit1)

test_data$pred <- fitted(fit1)
attach(test_data)
(sum((abs(clv-pred))/clv))/nrow(test_data)             ## Calculating MAPE





